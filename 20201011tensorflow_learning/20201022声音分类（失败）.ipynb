{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import librosa # conda install librosa\n",
    "from tqdm import tqdm # conda install tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2\n",
      "\n",
      "Parameters:\n",
      "ALSOLOGTOSTDERR=False\n",
      "BATCH_SIZE=50\n",
      "CHECKPOINT_EVERY=500\n",
      "DEV_SAMPLE_PERCENTAGE=0.2\n",
      "DROPOUT_KEEP_PROB=0.5\n",
      "EVALUATE_EVERY=50\n",
      "F=C:\\Users\\Administrator\\AppData\\Roaming\\jupyter\\runtime\\kernel-dc97ca02-1615-482e-a292-83731cc38c99.json\n",
      "LOG_DIR=\n",
      "LOGGER_LEVELS={}\n",
      "LOGTOSTDERR=False\n",
      "LR=0.005\n",
      "N_CLASSES=10\n",
      "N_HIDDEN=300\n",
      "N_INPUTS=40\n",
      "NUM_CHECKPOINTS=2\n",
      "NUM_EPOCHS=100\n",
      "ONLY_CHECK_ARGS=False\n",
      "OP_CONVERSION_FALLBACK_TO_WHILE_LOOP=False\n",
      "PARENT_DIR=audio/\n",
      "PDB=False\n",
      "PDB_POST_MORTEM=False\n",
      "PROFILE_FILE=None\n",
      "RUN_WITH_PDB=False\n",
      "RUN_WITH_PROFILING=False\n",
      "SHOWPREFIXFORINFO=True\n",
      "STDERRTHRESHOLD=fatal\n",
      "TEST_RANDOM_SEED=301\n",
      "TEST_RANDOMIZE_ORDERING_SEED=\n",
      "TEST_SRCDIR=\n",
      "TEST_TMPDIR=C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\absl_testing\n",
      "TR_SUB_DIRS=fold1/,fold2/,fold3/\n",
      "USE_CPROFILE_FOR_PROFILING=True\n",
      "V=-1\n",
      "VERBOSITY=-1\n",
      "XML_OUTPUT_FILE=\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/8241 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cffi library 'D:\\Anaconda3\\Library\\bin\\sndfile.dll' has no function, constant or global variable named 'sf_wchar_open'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-85a02409432b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[0mwav_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_wav_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtr_sub_dirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;31m# 获取文件mfcc特征和对应标签\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mtr_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr_features.npy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtr_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-85a02409432b>\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(wav_files)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mwav_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;31m# 读入音频文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0maudio\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwav_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# 获取音频mfcc特征\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    625\u001b[0m         self._info = _create_info_struct(file, mode, samplerate, channels,\n\u001b[0;32m    626\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 627\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;31m# Move write position to 0 (like in Python file objects)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1168\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_unicode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'win32'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1170\u001b[1;33m                     \u001b[0mopenfunction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_wchar_open\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1171\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m                     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfilesystemencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: cffi library 'D:\\Anaconda3\\Library\\bin\\sndfile.dll' has no function, constant or global variable named 'sf_wchar_open'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "flags = tf.app.flags\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "# Data loading params\n",
    "# validation数据集占比\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .2, \"Percentage of the training data to use for validation\")\n",
    "# 父目录\n",
    "tf.flags.DEFINE_string(\"parent_dir\", \"audio/\", \"Data source for the data.\")\n",
    "# 子目录\n",
    "tf.flags.DEFINE_string(\"tr_sub_dirs\", \"fold1/,fold2/,fold3/\", \"Data source for the data.\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "# 第一层输入，MFCC信号\n",
    "tf.flags.DEFINE_integer(\"n_inputs\", 40, \"Number of MFCCs (default: 40)\")\n",
    "# cell个数\n",
    "tf.flags.DEFINE_integer(\"n_hidden\", 300, \"Number of cells (default: 300)\")\n",
    "# 分类数\n",
    "tf.flags.DEFINE_integer(\"n_classes\", 10, \"Number of classes (default: 10)\")\n",
    "# 学习率\n",
    "tf.flags.DEFINE_float(\"lr\", 0.005, \"Learning rate (default: 0.005)\")\n",
    "# dropout参数\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "\n",
    "# Training parameters\n",
    "# 批次大小\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 50, \"Batch Size (default: 50)\")\n",
    "# 迭代周期\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 100, \"Number of training epochs (default: 100)\")\n",
    "# 多少step测试一次\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 50)\")\n",
    "# 多少step保存一次模型\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 500, \"Save model after this many steps (default: 500)\")\n",
    "# 最多保存多少个模型\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 2, \"Number of checkpoints to store (default: 2)\")\n",
    "\n",
    "\n",
    "# flags解析\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS.flag_values_dict()\n",
    "#单独打印某个变量\n",
    "print(FLAGS.dev_sample_percentage)\n",
    "\n",
    "# 打印所有参数\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.flag_values_dict().items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")\n",
    "\n",
    "# 获得训练用的wav文件路径列表  \n",
    "def get_wav_files(parent_dir,sub_dirs): \n",
    "    wav_files = []  \n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        wav_path = os.path.join(parent_dir, sub_dir)\n",
    "        #当前路径，文件目录，文件\n",
    "        for (dirpath, dirnames, filenames) in os.walk(wav_path):  \n",
    "            for filename in filenames:  \n",
    "                if filename.endswith('.wav') or filename.endswith('.WAV'):  \n",
    "                    filename_path = os.sep.join([dirpath, filename])  \n",
    "                    wav_files.append(filename_path)  \n",
    "    return wav_files  \n",
    "\n",
    "# 获取文件mfcc特征和对应标签\n",
    "def extract_features(wav_files):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    \n",
    "    #进度条\n",
    "    for wav_file in tqdm(wav_files):\n",
    "        # 读入音频文件\n",
    "        audio,fs = librosa.load(wav_file)\n",
    "\n",
    "        # 获取音频mfcc特征\n",
    "        # [n_steps, n_inputs]\n",
    "        mfccs = np.transpose(librosa.feature.mfcc(y=audio, sr=fs, n_mfcc=FLAGS.n_inputs), [1,0]) \n",
    "        inputs.append(mfccs.tolist()) \n",
    "    #获取label\n",
    "    for wav_file in wav_files:\n",
    "        label = wav_file.split('/')[-1].split('-')[1]\n",
    "        labels.append(label) \n",
    "    return inputs, np.array(labels, dtype=np.int)\n",
    "  \n",
    "# 获得训练用的wav文件路径列表 \n",
    "wav_files = get_wav_files(FLAGS.parent_dir,FLAGS.tr_sub_dirs)\n",
    "# 获取文件mfcc特征和对应标签\n",
    "tr_features,tr_labels = extract_features(wav_files)\n",
    "\n",
    "np.save('tr_features.npy',tr_features)\n",
    "np.save('tr_labels.npy',tr_labels)\n",
    "\n",
    "# tr_features=np.load('tr_features.npy')\n",
    "# tr_labels=np.load('tr_labels.npy')\n",
    "\n",
    "#(batch,step,input)\n",
    "#(50,173,40)\n",
    "\n",
    "# 计算最长的step\n",
    "wav_max_len = max([len(feature) for feature in tr_features])\n",
    "print(\"max_len:\",wav_max_len)\n",
    "\n",
    "# 填充0\n",
    "tr_data = []\n",
    "for mfccs in tr_features:  \n",
    "    while len(mfccs) < wav_max_len: #只要小于wav_max_len就补n_inputs个0\n",
    "        mfccs.append([0] * FLAGS.n_inputs) \n",
    "    tr_data.append(mfccs)\n",
    "\n",
    "tr_data = np.array(tr_data)\n",
    "\n",
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(tr_data)))\n",
    "x_shuffled = tr_data[shuffle_indices]\n",
    "y_shuffled = tr_labels[shuffle_indices]\n",
    "\n",
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "# 数据集切分为两部分\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y_shuffled)))\n",
    "train_x, test_x = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "train_y, test_y = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "\n",
    "# placeholder\n",
    "x = tf.placeholder(\"float\", [None, wav_max_len, FLAGS.n_inputs])\n",
    "y = tf.placeholder(\"float\", [None])\n",
    "dropout = tf.placeholder(tf.float32)\n",
    "# learning rate\n",
    "lr = tf.Variable(FLAGS.lr, dtype=tf.float32, trainable=False)\n",
    "\n",
    "# 定义RNN网络\n",
    "# 初始化权值和偏置\n",
    "weights = tf.Variable(tf.truncated_normal([FLAGS.n_hidden, FLAGS.n_classes], stddev=0.1))\n",
    "biases = tf.Variable(tf.constant(0.1, shape=[FLAGS.n_classes]))\n",
    "\n",
    "# 多层网络\n",
    "num_layers = 3\n",
    "def grucell():\n",
    "    cell = tf.contrib.rnn.GRUCell(FLAGS.n_hidden)\n",
    "#     cell = tf.contrib.rnn.LSTMCell(FLAGS.n_hidden)\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "    return cell\n",
    "cell = tf.contrib.rnn.MultiRNNCell([grucell() for _ in range(num_layers)])\n",
    "\n",
    "\n",
    "outputs,final_state = tf.nn.dynamic_rnn(cell,x,dtype=tf.float32)\n",
    "\n",
    "# 预测值\n",
    "prediction = tf.nn.softmax(tf.matmul(final_state[0],weights) + biases)\n",
    "# labels转one_hot格式\n",
    "one_hot_labels = tf.one_hot(indices=tf.cast(y, tf.int32), depth=FLAGS.n_classes)\n",
    "\n",
    "# loss\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=one_hot_labels))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cross_entropy)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction,1), tf.argmax(one_hot_labels,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "#样本生成器\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "        Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    # 每个epoch的num_batch 每个周期有多少个批次\n",
    "    num_batches_per_epoch = int((len(data) - 1) / batch_size) + 1\n",
    "    print(\"num_batches_per_epoch:\",num_batches_per_epoch)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]\n",
    "            \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "# 定义saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "\n",
    "    # Generate batches\n",
    "    batches = batch_iter(list(zip(train_x, train_y)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "\n",
    "    for i,batch in enumerate(batches):\n",
    "        i = i + 1\n",
    "        x_batch, y_batch = zip(*batch)\n",
    "        sess.run([optimizer], feed_dict={x: x_batch, y: y_batch, dropout: FLAGS.dropout_keep_prob})\n",
    "        \n",
    "        # 测试\n",
    "        if i % FLAGS.evaluate_every == 0:\n",
    "            sess.run(tf.assign(lr, FLAGS.lr * (0.99 ** (i // FLAGS.evaluate_every))))\n",
    "            learning_rate = sess.run(lr)\n",
    "            tr_acc, _loss = sess.run([accuracy, cross_entropy], feed_dict={x: train_x, y: train_y, dropout: 1.0})\n",
    "            ts_acc = sess.run(accuracy, feed_dict={x: test_x, y: test_y, dropout: 1.0})\n",
    "            print(\"Iter {}, loss {:.5f}, tr_acc {:.5f}, ts_acc {:.5f}, lr {:.5f}\".format(i, _loss, tr_acc, ts_acc, learning_rate))\n",
    "\n",
    "        # 保存模型\n",
    "        if i % FLAGS.checkpoint_every == 0:\n",
    "            path = saver.save(sess, \"sounds_models/model\", global_step=i)\n",
    "            print(\"Saved model checkpoint to {}\\n\".format(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
