{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the rock is destined to be the 21st century', 'effective but too-tepid biopic', 'if you sometimes like to go to the movies to have fun', 'the film provides some great insight into the neurotic mindset', 'take care of my cat offers a refreshingly']\n",
      "['the rock is destined to be the 21st century', 'effective but too tepid biopic', 'if you sometimes like to go to the movies to have fun', 'the film provides some great insight into the neurotic mindset', 'take care of my cat offers a refreshingly']\n"
     ]
    }
   ],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    # 不是特定字符都变成空格\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    # 加空格\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    # 匹配2个或多个空白字符变成一个\" \"空格\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    # 去掉句子首尾的空白符，再转小写\n",
    "    return string.strip().lower()\n",
    "\n",
    "positive_examples = ['the rock is destined to be the 21st century',\n",
    "                    'effective but too-tepid biopic',\n",
    "                    'if you sometimes like to go to the movies to have fun']\n",
    "positive_examples = [s.strip() for s in positive_examples]\n",
    "negative_examples=['the film provides some great insight into the neurotic mindset',\n",
    "                  'take care of my cat offers a refreshingly']\n",
    "negative_examples = [s.strip() for s in negative_examples]\n",
    "x_text = positive_examples + negative_examples\n",
    "print(x_text)\n",
    "x_text = [clean_str(sent) for sent in x_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [0, 1], [0, 1]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "positive_labels = [[0, 1] for _ in positive_examples]\n",
    "negative_labels = [[1, 0] for _ in negative_examples]\n",
    "print(positive_labels)\n",
    "y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "[[1 2 5]\n",
      " [3 4 6]]\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[5, 6]])\n",
    "c = np.concatenate((a,b),axis=0)\n",
    "d = np.concatenate((a,b.T),axis = 1)\n",
    "e = np.concatenate([a,b],0)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the movie 's ripe , enrapturing beauty will tempt those willing to probe its inscrutable mysteries !\n"
     ]
    }
   ],
   "source": [
    "string1 = \"the movie's ripe , enrapturing beauty will tempt those willing to probe its inscrutable mysteries! \"\n",
    "string2 = clean_str(string1)\n",
    "print(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 5, 12, 10, 8]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "document_len = [len(x.split(\" \")) for x in x_text]\n",
    "print(document_len)\n",
    "max_len = max(document_len)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  1  7  8  0  0  0]\n",
      " [ 9 10 11 12 13  0  0  0  0  0  0  0]\n",
      " [14 15 16 17  5 18  5  1 19  5 20 21]\n",
      " [ 1 22 23 24 25 26 27  1 28 29  0  0]\n",
      " [30 31 32 33 34 35 36 37  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "vocab = learn.preprocessing.VocabularyProcessor(max_len)\n",
    "#将列表转换为数组\n",
    "x = np.array(list(vocab.fit_transform(x_text)))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机排序列表 :  [20, 16, 10, 5]\n",
      "随机排序列表 :  [10, 20, 5, 16]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "list1 = [20, 16, 10, 5]\n",
    "random.shuffle(list1)\n",
    "print(\"随机排序列表 : \",  list1)\n",
    "\n",
    "random.shuffle(list1)\n",
    "print(\"随机排序列表 : \",  list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first: [0.5507979  0.70814782 0.29090474 0.51082761 0.89294695]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "np.random.seed(3)\n",
    "a = rand(5)\n",
    "print(\"first:\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second: [0.5507979  0.70814782 0.29090474 0.51082761 0.89294695]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "a = rand(5)\n",
    "print(\"second:\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "#数字0-4排序\n",
    "b = np.random.permutation(5)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 3 2 0 5 1 7 8 6]\n"
     ]
    }
   ],
   "source": [
    "#list排序\n",
    "c = np.random.permutation([1,2,3,4,5,6,7,8,9,0])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "aa = np.arange(3)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "bb = np.arange(3,9)\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 5 7 9]\n"
     ]
    }
   ],
   "source": [
    "cc = np.arange(1,10,2)#起点1，终点10，步长2\n",
    "print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  1  7  8  0  0  0]\n",
      " [ 9 10 11 12 13  0  0  0  0  0  0  0]\n",
      " [14 15 16 17  5 18  5  1 19  5 20 21]\n",
      " [ 1 22 23 24 25 26 27  1 28 29  0  0]\n",
      " [30 31 32 33 34 35 36 37  0  0  0  0]]\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n",
      "______\n",
      "[[14 15 16 17  5 18  5  1 19  5 20 21]\n",
      " [ 1 22 23 24 25 26 27  1 28 29  0  0]\n",
      " [ 1  2  3  4  5  6  1  7  8  0  0  0]\n",
      " [30 31 32 33 34 35 36 37  0  0  0  0]\n",
      " [ 9 10 11 12 13  0  0  0  0  0  0  0]]\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(\"______\")\n",
    "np.random.seed(10)\n",
    "shuffle_indices1 = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices1]\n",
    "y_shuffled = y[shuffle_indices1]\n",
    "print(x_shuffled)\n",
    "print(y_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.08788133  0.22054613 -0.03172755 -0.13382006  0.26269603  0.35440767]\n",
      " [ 0.09093058  0.12063205 -0.3468814  -0.00612164 -0.47694886  0.31444407]\n",
      " [-0.35818386  0.23495948  0.4968568  -0.13550162 -0.29231262 -0.49774373]\n",
      " [-0.36301184  0.15901637  0.02170622 -0.29145586 -0.2537732   0.20505822]\n",
      " [ 0.06371689  0.07469189 -0.08913267  0.01038587 -0.28714263  0.34437072]\n",
      " [-0.43197167 -0.15391958  0.3788265  -0.10389376 -0.47904682  0.3731209 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.random_uniform(\n",
    "        (6,6), minval=-0.5,\n",
    "        maxval=0.5, dtype=tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'how'), (1, 'are'), (2, 'you')]\n"
     ]
    }
   ],
   "source": [
    "#enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
    "data1 = ['how','are','you']\n",
    "print(list(enumerate(data1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]]\n"
     ]
    }
   ],
   "source": [
    "#shape\n",
    "arr1= np.array([1,2,3,4,5,6,7,8])\n",
    "print(arr1)\n",
    "arr2 = arr1.reshape(2,4)\n",
    "print(arr2)\n",
    "arr3 = arr1.reshape(2,2,2)\n",
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-cd8e3c46e6c7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-cd8e3c46e6c7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python train.py\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'dev_sample_percentage' is defined twice. First from train.py, Second from train.py.  Description from first occurrence: Percentage of the training data to use for validation",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mD:\\Tensorflow\\20201014cnn-text-classification\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Data loading params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dev_sample_percentage\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Percentage of the training data to use for validation\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"positive_data_file\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./data/rt-polaritydata/rt-polarity.pos\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Data source for the positive data.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"negative_data_file\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./data/rt-polaritydata/rt-polarity.neg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Data source for the negative data.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\flags.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m           \u001b[1;34m'Use of the keyword argument names (flag_name, default_value, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m           'docstring) is deprecated, please use (name, default, help) instead.')\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_float\u001b[1;34m(name, default, help, lower_bound, upper_bound, flag_values, **args)\u001b[0m\n\u001b[0;32m    333\u001b[0m   \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDEFINE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m   \u001b[0m_register_bounds_validator_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflag_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[1;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[0;32m    101\u001b[0m   return DEFINE_flag(\n\u001b[0;32m    102\u001b[0m       \u001b[0m_flag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m       module_name)\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[1;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[0;32m    126\u001b[0m   \u001b[1;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m   \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m   \u001b[0mfv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m   \u001b[1;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, flag)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[1;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateFlagError\u001b[0m: The flag 'dev_sample_percentage' is defined twice. First from train.py, Second from train.py.  Description from first occurrence: Percentage of the training data to use for validation"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
